{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>count</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>rolling_mean_3</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_mean_14</th>\n",
       "      <th>rolling_mean_30</th>\n",
       "      <th>rolling_median_3</th>\n",
       "      <th>rolling_median_7</th>\n",
       "      <th>rolling_median_14</th>\n",
       "      <th>rolling_median_30</th>\n",
       "      <th>rolling_std_3</th>\n",
       "      <th>rolling_std_7</th>\n",
       "      <th>rolling_std_14</th>\n",
       "      <th>rolling_std_30</th>\n",
       "      <th>rolling_min_3</th>\n",
       "      <th>rolling_min_7</th>\n",
       "      <th>rolling_min_14</th>\n",
       "      <th>rolling_min_30</th>\n",
       "      <th>rolling_max_3</th>\n",
       "      <th>rolling_max_7</th>\n",
       "      <th>rolling_max_14</th>\n",
       "      <th>rolling_max_30</th>\n",
       "      <th>expanding_mean</th>\n",
       "      <th>expanding_median</th>\n",
       "      <th>expanding_std</th>\n",
       "      <th>expanding_min</th>\n",
       "      <th>expanding_max</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>diff_7</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.979530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724793</td>\n",
       "      <td>0.688967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848644</td>\n",
       "      <td>0.528964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PULocationID pickup_date  count  day_of_week  day_of_month  month  \\\n",
       "0            1  2022-02-01      0            1             1      2   \n",
       "1            1  2022-02-02      0            2             2      2   \n",
       "2            1  2022-02-03      0            3             3      2   \n",
       "3            1  2022-02-04      0            4             4      2   \n",
       "4            1  2022-02-05      0            5             5      2   \n",
       "\n",
       "   is_weekend  lag_1  lag_7  rolling_mean_3  rolling_mean_7  rolling_mean_14  \\\n",
       "0           0    0.0    0.0             0.0             0.0              0.0   \n",
       "1           0    0.0    0.0             0.0             0.0              0.0   \n",
       "2           0    0.0    0.0             0.0             0.0              0.0   \n",
       "3           0    0.0    0.0             0.0             0.0              0.0   \n",
       "4           1    0.0    0.0             0.0             0.0              0.0   \n",
       "\n",
       "   rolling_mean_30  rolling_median_3  rolling_median_7  rolling_median_14  \\\n",
       "0              0.0               0.0               0.0                0.0   \n",
       "1              0.0               0.0               0.0                0.0   \n",
       "2              0.0               0.0               0.0                0.0   \n",
       "3              0.0               0.0               0.0                0.0   \n",
       "4              0.0               0.0               0.0                0.0   \n",
       "\n",
       "   rolling_median_30  rolling_std_3  rolling_std_7  rolling_std_14  \\\n",
       "0                0.0            0.0            0.0             0.0   \n",
       "1                0.0            0.0            0.0             0.0   \n",
       "2                0.0            0.0            0.0             0.0   \n",
       "3                0.0            0.0            0.0             0.0   \n",
       "4                0.0            0.0            0.0             0.0   \n",
       "\n",
       "   rolling_std_30  rolling_min_3  rolling_min_7  rolling_min_14  \\\n",
       "0             0.0            0.0            0.0             0.0   \n",
       "1             0.0            0.0            0.0             0.0   \n",
       "2             0.0            0.0            0.0             0.0   \n",
       "3             0.0            0.0            0.0             0.0   \n",
       "4             0.0            0.0            0.0             0.0   \n",
       "\n",
       "   rolling_min_30  rolling_max_3  rolling_max_7  rolling_max_14  \\\n",
       "0             0.0            0.0            0.0             0.0   \n",
       "1             0.0            0.0            0.0             0.0   \n",
       "2             0.0            0.0            0.0             0.0   \n",
       "3             0.0            0.0            0.0             0.0   \n",
       "4             0.0            0.0            0.0             0.0   \n",
       "\n",
       "   rolling_max_30  expanding_mean  expanding_median  expanding_std  \\\n",
       "0             0.0             0.0               0.0            0.0   \n",
       "1             0.0             0.0               0.0            0.0   \n",
       "2             0.0             0.0               0.0            0.0   \n",
       "3             0.0             0.0               0.0            0.0   \n",
       "4             0.0             0.0               0.0            0.0   \n",
       "\n",
       "   expanding_min  expanding_max  diff_1  diff_7  day_of_week_sin  \\\n",
       "0            0.0            0.0     0.0     0.0         0.201299   \n",
       "1            0.0            0.0     0.0     0.0         0.394356   \n",
       "2            0.0            0.0     0.0     0.0         0.571268   \n",
       "3            0.0            0.0     0.0     0.0         0.724793   \n",
       "4            0.0            0.0     0.0     0.0         0.848644   \n",
       "\n",
       "   day_of_week_cos  \n",
       "0         0.979530  \n",
       "1         0.918958  \n",
       "2         0.820763  \n",
       "3         0.688967  \n",
       "4         0.528964  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv(\"../data/processed/fhvhv_daily_counts_features.csv\")\n",
    "\n",
    "full_df['pickup_date'] = pd.to_datetime(full_df['pickup_date'])\n",
    "# set PULocationID as categorical\n",
    "full_df[\"PULocationID\"] = full_df[\"PULocationID\"].astype(\"category\")\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-09-23 00:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOLDOUT_LENGTH_W = 1\n",
    "\n",
    "HOLDOUT_DATE_START = full_df.pickup_date.max() - pd.Timedelta(weeks=HOLDOUT_LENGTH_W)\n",
    "\n",
    "HOLDOUT_DATE_START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_df = full_df[full_df.pickup_date > HOLDOUT_DATE_START]\n",
    "\n",
    "df = full_df[full_df.pickup_date <= HOLDOUT_DATE_START]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 157800 entries, 0 to 159633\n",
      "Data columns (total 38 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   PULocationID       157800 non-null  category      \n",
      " 1   pickup_date        157800 non-null  datetime64[ns]\n",
      " 2   count              157800 non-null  int64         \n",
      " 3   day_of_week        157800 non-null  int64         \n",
      " 4   day_of_month       157800 non-null  int64         \n",
      " 5   month              157800 non-null  int64         \n",
      " 6   is_weekend         157800 non-null  int64         \n",
      " 7   lag_1              157800 non-null  float64       \n",
      " 8   lag_7              157800 non-null  float64       \n",
      " 9   rolling_mean_3     157800 non-null  float64       \n",
      " 10  rolling_mean_7     157800 non-null  float64       \n",
      " 11  rolling_mean_14    157800 non-null  float64       \n",
      " 12  rolling_mean_30    157800 non-null  float64       \n",
      " 13  rolling_median_3   157800 non-null  float64       \n",
      " 14  rolling_median_7   157800 non-null  float64       \n",
      " 15  rolling_median_14  157800 non-null  float64       \n",
      " 16  rolling_median_30  157800 non-null  float64       \n",
      " 17  rolling_std_3      157800 non-null  float64       \n",
      " 18  rolling_std_7      157800 non-null  float64       \n",
      " 19  rolling_std_14     157800 non-null  float64       \n",
      " 20  rolling_std_30     157800 non-null  float64       \n",
      " 21  rolling_min_3      157800 non-null  float64       \n",
      " 22  rolling_min_7      157800 non-null  float64       \n",
      " 23  rolling_min_14     157800 non-null  float64       \n",
      " 24  rolling_min_30     157800 non-null  float64       \n",
      " 25  rolling_max_3      157800 non-null  float64       \n",
      " 26  rolling_max_7      157800 non-null  float64       \n",
      " 27  rolling_max_14     157800 non-null  float64       \n",
      " 28  rolling_max_30     157800 non-null  float64       \n",
      " 29  expanding_mean     157800 non-null  float64       \n",
      " 30  expanding_median   157800 non-null  float64       \n",
      " 31  expanding_std      157800 non-null  float64       \n",
      " 32  expanding_min      157800 non-null  float64       \n",
      " 33  expanding_max      157800 non-null  float64       \n",
      " 34  diff_1             157800 non-null  float64       \n",
      " 35  diff_7             157800 non-null  float64       \n",
      " 36  day_of_week_sin    157800 non-null  float64       \n",
      " 37  day_of_week_cos    157800 non-null  float64       \n",
      "dtypes: category(1), datetime64[ns](1), float64(31), int64(5)\n",
      "memory usage: 46.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKTESTS = 3\n",
    "BACKTESTS_LENGTH_W = 1\n",
    "\n",
    "def split_train_test_by_date(df, BACKTESTS=BACKTESTS, BACKTESTS_LENGTH_W=BACKTESTS_LENGTH_W):\n",
    "    \"\"\"\n",
    "    Splits a dataframe into train and test sets by date. Create BACKTESTS number of backtests, each BACKTESTS_LENGTH_W weeks long.\n",
    "    We will do moving window backtests\n",
    "    \"\"\"\n",
    "\n",
    "    TRAIN_START = df.pickup_date.min() - pd.Timedelta(days=1)\n",
    "    TRAIN_LENGTH = df.pickup_date.max() - pd.Timedelta(weeks=BACKTESTS_LENGTH_W*BACKTESTS) - TRAIN_START\n",
    "\n",
    "    end = df.pickup_date.max()\n",
    "    earliest_train_start = df.pickup_date.min()\n",
    "\n",
    "    train_val_pairs = []\n",
    "    for i in range(BACKTESTS):\n",
    "        backtest_end = end - pd.Timedelta(days=1)  # End date of backtest is one day before holdout starts\n",
    "        backtest_start = backtest_end - pd.Timedelta(weeks=BACKTESTS_LENGTH_W) + pd.Timedelta(days=1)\n",
    "\n",
    "        train_start = earliest_train_start + pd.Timedelta(weeks=BACKTESTS_LENGTH_W*(BACKTESTS - i-1))\n",
    "        train_end = backtest_start - pd.Timedelta(days=1)\n",
    "\n",
    "        # print(f\"Backtest {i+1}:\")\n",
    "        # print(f\"   Training Data: Start - {train_start.date()}, End - {train_end.date()}\")\n",
    "        # print(f\"   Backtest Data: Start - {backtest_start.date()}, End - {backtest_end.date()}\")\n",
    "\n",
    "        train_df = df[(df.pickup_date >= train_start) & (df.pickup_date <= train_end)]\n",
    "        test_df = df[(df.pickup_date >= backtest_start) & (df.pickup_date <= backtest_end)]\n",
    "\n",
    "        train_val_pairs.append((train_df, test_df))\n",
    "\n",
    "        end = backtest_start\n",
    "\n",
    "    return train_val_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = {'n_estimators':300, 'learning_rate':0.1, 'max_depth':5, \n",
    "                      'min_child_weight':1, 'gamma':0, 'subsample':1, 'colsample_bytree':0.3, 'alpha':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(train_df, test_df = None, parameters = default_parameters, ):\n",
    "\n",
    "    early_stopping_rounds = None\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"pickup_date\", \"count\"])\n",
    "    y_train = train_df[\"count\"]\n",
    "\n",
    "    if test_df is not None:\n",
    "        X_test = test_df.drop(columns=[\"pickup_date\", \"count\"])\n",
    "        y_test = test_df[\"count\"]\n",
    "\n",
    "        xg_reg = XGBRegressor(**parameters,\n",
    "                          objective = \"reg:squarederror\", eval_metric = \"rmse\", seed = 123, n_jobs = -1, enable_categorical = True, \n",
    "                          early_stopping_rounds=10)\n",
    "\n",
    "        xg_reg.fit(X_train,y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=False)\n",
    "\n",
    "    else:\n",
    "        xg_reg = XGBRegressor(**parameters,\n",
    "                    objective = \"reg:squarederror\", eval_metric = \"rmse\", seed = 123, n_jobs = -1, enable_categorical = True)\n",
    "\n",
    "        xg_reg.fit(X_train,y_train)\n",
    "\n",
    "    return xg_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating optimisation with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -7, 0),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 15, 1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -2, 3),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1),\n",
    "    'n_estimators': hp.quniform('n_estimators', 200, 750, 50),\n",
    "    'gamma': hp.loguniform('gamma', -2, 3),\n",
    "    'alpha': hp.loguniform('alpha', -2, 3),\n",
    "    'lambda': hp.loguniform('lambda', -2, 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    params = {\n",
    "        'learning_rate': space['learning_rate'],\n",
    "        'max_depth': int(space['max_depth']),\n",
    "        'min_child_weight': space['min_child_weight'],\n",
    "        'subsample': space['subsample'],\n",
    "        'colsample_bytree': space['colsample_bytree'],\n",
    "        'gamma': space['gamma'],\n",
    "        'alpha': space['alpha'],\n",
    "        'lambda': space['lambda'],\n",
    "        'n_estimators': int(space['n_estimators']),\n",
    "    }\n",
    "    LOSS = []\n",
    "    for j, (train, test) in enumerate(split_train_test_by_date(TRAIN_DF)):\n",
    "        model_xgb_opt_cv = train_xgb(train, test, parameters=params)\n",
    "\n",
    "        pred = model_xgb_opt_cv.predict(test.drop(columns=[\"pickup_date\", \"count\"]))\n",
    "    \n",
    "        loss_model = rmse(test[\"count\"], pred)\n",
    "    \n",
    "    LOSS.append(loss_model)\n",
    "\n",
    "    loss = np.mean(LOSS)\n",
    "    \n",
    "    return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()  \n",
    "n_iter = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "We optimise the hyperparameters of the model using the hyperopt library.\n",
    "The optimisation will happen on the latest (most recent) backtest.\n",
    "\n",
    "Then we will just train the model with the best hyperparameters on the other backtests and evaluate it separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt.early_stop import no_progress_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT PARAMETERS ARE: {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0, 'subsample': 1, 'colsample_bytree': 0.3, 'alpha': 10}\n",
      " 70%|███████   | 14/20 [18:44<08:02, 80.34s/trial, best loss: 199.1131041015372]\n"
     ]
    }
   ],
   "source": [
    "train, test = split_train_test_by_date(df)[0]\n",
    "\n",
    "print(\"DEFAULT PARAMETERS ARE: {}\".format(default_parameters))\n",
    "        # do internal CV on first backtest\n",
    "TRAIN_DF = train.copy()\n",
    "\n",
    "best=fmin(fn=objective, space=search_space, algo=tpe.suggest,\n",
    "max_evals=20,\n",
    "trials=trials,\n",
    "early_stop_fn=no_progress_loss(10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 7.770483145979562,\n",
       " 'colsample_bytree': 0.6212693715774648,\n",
       " 'gamma': 7.446473540559165,\n",
       " 'lambda': 0.580758896382699,\n",
       " 'learning_rate': 0.015156138623413178,\n",
       " 'max_depth': 14.0,\n",
       " 'min_child_weight': 4.733033609230644,\n",
       " 'n_estimators': 700.0,\n",
       " 'subsample': 0.7801290200553479}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 7.770483145979562,\n",
       " 'colsample_bytree': 0.6212693715774648,\n",
       " 'gamma': 7.446473540559165,\n",
       " 'lambda': 0.580758896382699,\n",
       " 'learning_rate': 0.015156138623413178,\n",
       " 'max_depth': 14,\n",
       " 'min_child_weight': 4.733033609230644,\n",
       " 'n_estimators': 700,\n",
       " 'subsample': 0.7801290200553479}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy best parameters to default parameters\n",
    "best_parameters_final = best.copy() \n",
    "best_parameters_final['max_depth'] = int(best_parameters_final['max_depth'])\n",
    "best_parameters_final['n_estimators'] = int(best_parameters_final['n_estimators'])\n",
    "best_parameters_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_final = {\n",
    "#  'alpha': 0.5646387212271088,\n",
    "#  'colsample_bytree': 0.6585122987835552,\n",
    "#  'gamma': 0.8069274373476782,\n",
    "#  'lambda': 13.622702434901178,\n",
    "#  'learning_rate': 0.05005038815036528,\n",
    "#  'max_depth': 39,\n",
    "#  'min_child_weight': 0.3787276602617831,\n",
    "#  'n_estimators': 579,\n",
    "#  'subsample': 0.9560746826764644}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL IS TUNED. BEST HYPERPARAMETERS ARE: {'alpha': 7.770483145979562, 'colsample_bytree': 0.6212693715774648, 'gamma': 7.446473540559165, 'lambda': 0.580758896382699, 'learning_rate': 0.015156138623413178, 'max_depth': 14, 'min_child_weight': 4.733033609230644, 'n_estimators': 700, 'subsample': 0.7801290200553479}\n",
      "RMSE for backtest 0 is 251.7098825972449\n",
      "RMSE for backtest 1 is 118.94386613148271\n",
      "RMSE for backtest 2 is 145.39392073141966\n"
     ]
    }
   ],
   "source": [
    "for i, (train, test) in enumerate(split_train_test_by_date(df)):\n",
    "    \n",
    "\n",
    "    if i==0:\n",
    "\n",
    "        print(\"MODEL IS TUNED. BEST HYPERPARAMETERS ARE: {}\".format(best_parameters_final))\n",
    "\n",
    "        tuned_model = train_xgb(train, test, best_parameters_final)\n",
    "        prediction = tuned_model.predict(test.drop(columns=[\"pickup_date\", \"count\"]))\n",
    "\n",
    "        print(\"RMSE for backtest {} is {}\".format(i, rmse(test['count'], prediction)))\n",
    "        \n",
    "\n",
    "    else:\n",
    "        # model_xgb = train_xgb(train, best_parameters_final)\n",
    "\n",
    "        prediction = tuned_model.predict(test.drop(columns=[\"pickup_date\", \"count\"]))\n",
    "        \n",
    "        print(\"RMSE for backtest {} is {}\".format(i, rmse(test['count'], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for holdout is 383.7053058807188\n"
     ]
    }
   ],
   "source": [
    "# train on all data to evaluate on holdout\n",
    "final_model = train_xgb(df, test_df = None, parameters = best_parameters_final)\n",
    "\n",
    "#predict on hodlout\n",
    "holdout_prediction = final_model.predict(holdout_df.drop(columns=[\"pickup_date\", \"count\"]))\n",
    "print(\"RMSE for holdout is {}\".format(rmse(holdout_df['count'], holdout_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on full_df\n",
    "final_model = train_xgb(full_df, parameters = best_parameters_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model using timestamp\n",
    "\n",
    "final_model.save_model(\"../models/xgb_{}.json\".format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tlc-nyc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
